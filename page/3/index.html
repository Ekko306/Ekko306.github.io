<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">

<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: black; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.1">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.1" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.1">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.4.1',
    exturl: false,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="You are my JavaSript in my HTML.">
<meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="You are my JavaSript in my HTML.">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
<meta name="twitter:description" content="You are my JavaSript in my HTML.">
  <link rel="canonical" href="http://yoursite.com/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Hexo</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

<script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>


  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

    

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <div id="posts" class="posts-expand">
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/18/CNN重读笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="望星的太阳花">
      <meta itemprop="description" content="You are my JavaSript in my HTML.">
      <meta itemprop="image" content="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1570163730249&di=dcd36b04d1066a90ddb1f132ae3a6bcc&imgtype=0&src=http%3A%2F%2Fhbimg.b0.upaiyun.com%2Ffe60497fd762440686b6d5702c2c9f19df71fb9911009-LVWEJj_fw658">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/10/18/CNN重读笔记/" class="post-title-link" itemprop="url">CNN重读笔记</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2019-10-18 15:16:55" itemprop="dateCreated datePublished" datetime="2019-10-18T15:16:55+08:00">2019-10-18</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-11 12:05:53" itemprop="dateModified" datetime="2020-02-11T12:05:53+08:00">2020-02-11</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep-Learning</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="CNN重读笔记"><a href="#CNN重读笔记" class="headerlink" title="CNN重读笔记"></a>CNN重读笔记</h1><p>因为后续实验重点要掌握应用图像识别，这里深入归纳一下CNN。</p>
<h2 id="章节框架"><a href="#章节框架" class="headerlink" title="章节框架"></a>章节框架</h2><p><img src="/2019/10/18/CNN重读笔记/CNN%E6%A1%86%E6%9E%B6.png" alt="CNN框架"><br>由上图可见这章，先介绍CNN起源，再介绍卷积神经网络的理论概念，跟着PyTorch的CNN实现，后面是两个拓展：实用的CNN实例与项目，图片增强方法与实例</p>
<h2 id="4-1-主要任务及起源"><a href="#4-1-主要任务及起源" class="headerlink" title="4.1 主要任务及起源"></a>4.1 主要任务及起源</h2><p>在卷积神经网络流行起来之前，图像处理使用的都是→些传统的方法.比如提取图像中的边缘、纹理、线条、边界等特征，依据这些特征再进行下一步的处理，这样的处理不仅效率特别低，准确率也不高。 归功于卷积神经网络。</p>
<h2 id="4-2-卷积神经网络的原理和结构"><a href="#4-2-卷积神经网络的原理和结构" class="headerlink" title="4.2 卷积神经网络的原理和结构"></a>4.2 卷积神经网络的原理和结构</h2><h3 id="4-2-0-概述"><a href="#4-2-0-概述" class="headerlink" title="4.2.0 概述"></a>4.2.0 概述</h3><p>三个观点让卷积神经网络真正起作用</p>
<ol>
<li>局部性：特征不是整张图片决定的，而是一些局部的特征决定的，如看鸟看鸟嘴。</li>
<li>相同性：特征出现在不同位置，但是决定相同的特征机制是一样的，如不同鸟都有鸟嘴。</li>
<li>不变性：一张大图片，进行图片缩小也不会影响图片的性质。<hr>
</li>
</ol>
<ul>
<li><strong>卷积神经网络与全连接神经网络不同：</strong><ul>
<li><strong>全连接网络神经网络</strong>由一系列隐藏层构成，每个隐藏层由若干神经元构成，其中每个神经元都和前一层的所有神经元相关联，但每一层的神经元是相互独立的。<br><img src="/2019/10/18/CNN重读笔记/diff.png" alt="diff"></li>
<li><strong>卷积神经网络</strong>不同于一般的全连接神经网络，卷积神经网络是一个3D容量的神经元，通过宽度，高度和深度来排列。主要层结构有三个:卷积层、池化层和全连接层，通过堆叠这些层结构形成了一个完整的卷积神经网络结构。<br><img src="/2019/10/18/CNN重读笔记/CNN%E7%BB%93%E6%9E%84.png" alt="CNN结构"></li>
</ul>
</li>
</ul>
<h3 id="4-2-1-卷积层"><a href="#4-2-1-卷积层" class="headerlink" title="4.2.1 卷积层"></a>4.2.1 卷积层</h3><p><strong><em>这里插入题外思考，想了半天不理解为啥卷积神经网络是这个样子，其实就是长宽只扫描3x3或者5x5实际上有30x30或者更大，然后零层可以让输入的个数等于输出的个数，这只是一层卷积层，这个里面包含了滤波器就是一小块，滤波器的参数是可以学习的，而全连接神经网络就是可以将所有的输出都输入给下一个层，当然层数越复杂 模型可以学习的参数也越多 拟合效果越好，时间越长。卷积神经网络只提取部分的，然后分析。阿哈 终于懂了</em></strong><br><img src="/2019/10/18/CNN重读笔记/%E5%85%A8%E8%BF%9E%E6%8E%A5.png" alt="全连接"></p>
<hr>

<ul>
<li><p>要点</p>
<ul>
<li>局部连接 只获取局部的参数（图像局部性）</li>
<li>空间排列 输出深度、滑动步长，以及边界填充控制着卷积层的空间排布。</li>
<li>零填充的使用 来让输入大小等于输出大小</li>
<li>步长 配合与零填充使用</li>
<li><strong>参数共享</strong>：单个滤波器可以扫描到相同的特征（图像相同性）,就可以把参数减少，如下。这里相同性也不总是有用的，比如人脸识别就需要某个位置有某个特征与位置有关了。<hr>
</li>
</ul>
<p> <strong><em>问题</em></strong></p>
<p> <img src="/2019/10/18/CNN重读笔记/%E6%BB%A4%E6%B3%A2%E5%99%A8.png" alt="滤波器"></p>
 <hr>

<p> <img src="/2019/10/18/CNN重读笔记/solution.png" alt="solution"><br> <strong><em>上面又想半天，滤波器就是提取激活学习的层数，32个层数是自己指定的，你可以任意增加滤波器的个数结果输出图片的深度会增加，然后3x3x10是单个滤波器扫描得到的参数，这个10要和输入图片的深度一致，如上图输入6x6x3，输出4x4x2，然后开头的20x20就是输入的图片大小可以指定3x3参数合适让输出也等于20x20</em></strong></p>
<hr>

</li>
</ul>
<p><img src="/2019/10/18/CNN重读笔记/%E6%80%BB%E7%BB%93.png" alt="总结"></p>
<h3 id="4-2-2-池化层"><a href="#4-2-2-池化层" class="headerlink" title="4.2.2 池化层"></a>4.2.2 池化层</h3><blockquote>
<p>池化层作用是逐渐降低数据体的空间尺 寸.这样就能够减少网络中参数的数量 .减少计算资服耗费， 同时也能够有效地控制过 拟合。</p>
</blockquote>
<p>依据图片的不变性，将一个层的大小变小也不会改变值。</p>
<p><strong>总结</strong><br><img src="/2019/10/18/CNN重读笔记/pooling.png" alt="pooling"></p>
<h3 id="4-2-3-全连接层"><a href="#4-2-3-全连接层" class="headerlink" title="4.2.3 全连接层"></a>4.2.3 全连接层</h3><p>一般经过卷积层和池化层之后再经过一个全连接层，将3D的立方体重新排列变成全全连接层，再经过几个隐藏层，最后得到结果。<br>一般会添加dropout防止过拟合</p>
<h3 id="4-2-4-卷积神经网络的基本形式"><a href="#4-2-4-卷积神经网络的基本形式" class="headerlink" title="4.2.4 卷积神经网络的基本形式"></a>4.2.4 卷积神经网络的基本形式</h3><p>基本由以上三个层构成，还会添加激活函数来增加非线性，也会增加批标准化等权重初始化的函数等等来缩小图像，最后全连接层展开，一般结构：<br><strong><em>卷积层&rarr;ReLU层&rarr;批标准化层&rarr;池化层&rarr;…&rarr;全连接层</em></strong><br><strong>1，小滤波器的有效性</strong><br><img src="/2019/10/18/CNN重读笔记/77v33.png" alt="77v33"><br>多个小卷积层比单个大卷积层效果好，上图同时感受野同是7x7，大的有7x7xCxC=49C<sup>2</sup>，小的有3x(3x3)xCxC=49C<sup>2</sup>，参数变小。同时多个小卷积层增加了复杂度。<br><strong>2，网络的尺寸</strong><br>根据经验会有一些规则无严格数学证明。<br><img src="/2019/10/18/CNN重读笔记/size.png" alt="size"></p>
<h2 id="4-3-PyTorch卷积模块"><a href="#4-3-PyTorch卷积模块" class="headerlink" title="4.3 PyTorch卷积模块"></a>4.3 PyTorch卷积模块</h2><p>在nn这个模块包中调用卷积神经的层结构</p>
<h3 id="4-3-1-卷积层"><a href="#4-3-1-卷积层" class="headerlink" title="4.3.1 卷积层"></a>4.3.1 卷积层</h3><p><img src="/2019/10/18/CNN重读笔记/nn.Conv2d().png" alt="nn.Conv2d()"></p>
<h3 id="4-3-2-池化层"><a href="#4-3-2-池化层" class="headerlink" title="4.3.2 池化层"></a>4.3.2 池化层</h3><p><img src="/2019/10/18/CNN重读笔记/nn.MaxPool2d().png" alt="nn.MaxPool2d()"><br>构造简单的卷积神经网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleCNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(SimpleCNN, self).__init__()</span><br><span class="line">        layer1 = nn.Sequential()</span><br><span class="line">        layer1.add_module(<span class="string">'conv1'</span>, nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>, padding=<span class="number">1</span>)) <span class="comment"># b, 32, 32, 32</span></span><br><span class="line">        layer1.add_module(<span class="string">'relu1'</span>, nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        layer1.add_module(<span class="string">'pool1'</span>, nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)) <span class="comment">#b, 32, 16, 16</span></span><br><span class="line">        self.layer1 = layer1</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        layer2 = nn.Sequential()</span><br><span class="line">        layer2.add_module(<span class="string">'conv2'</span>, nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>, padding=<span class="number">1</span>)) <span class="comment">#b, 64, 16, 16</span></span><br><span class="line">        layer2.add_module(<span class="string">'relu2'</span>, nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        layer2.add_module(<span class="string">'pool2'</span>, nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)) <span class="comment">#b, 64, 8, 8</span></span><br><span class="line">        self.layer2 = layer2</span><br><span class="line">        </span><br><span class="line">        layer3 = nn.Sequential()</span><br><span class="line">        layer3.add_module(<span class="string">'conv3'</span>, nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, padding=<span class="number">1</span>)) <span class="comment"># 128, 8, 8</span></span><br><span class="line">        layer3.add_module(<span class="string">'relu3'</span>, nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        layer3.add_module(<span class="string">'pool3'</span>, nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)) <span class="comment">#b, 128, 4, 4</span></span><br><span class="line">        self.layer3 = layer3</span><br><span class="line">        </span><br><span class="line">        layer4 = nn.Sequential()</span><br><span class="line">        layer4.add_module(<span class="string">'fc1'</span>, nn.Linear(<span class="number">2048</span>, <span class="number">512</span>))</span><br><span class="line">        layer4.add_module(<span class="string">'fc_relu1'</span>, nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        layer4.add_module(<span class="string">'fc2'</span>, nn.Linear(<span class="number">512</span>, <span class="number">64</span>))</span><br><span class="line">        layer4.add_module(<span class="string">'fc_relu2'</span>, nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        layer4.add_module(<span class="string">'fc3'</span>, nn.Linear(<span class="number">64</span>, <span class="number">10</span>))</span><br><span class="line">        self.layer4 = layer4</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        conv1 = self.layer1(x)</span><br><span class="line">        conv2 = self.layer2(conv1)</span><br><span class="line">        conv3 = self.layer3(conv2)</span><br><span class="line">        fc_input = conv3.view(conv3.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        fc_out = self.layer4(fc_input)</span><br><span class="line">        <span class="keyword">return</span> fc_out</span><br><span class="line">model = SimpleCNN()</span><br></pre></td></tr></table></figure>

<p>概括上面：将卷积层、激活层和池化层组合乘一个层结构，定义3个这样层结构，最后定义全连接层，输出10.<br>也可以在forward添加输出中间层观察中间层输出。<br>还可以print(model)显示哪些层结构</p>
<h3 id="4-3-3-提取层结构"><a href="#4-3-3-提取层结构" class="headerlink" title="4.3.3 提取层结构"></a>4.3.3 提取层结构</h3><p>对于一个给定的模型，如果不想要模型中所有的层结构，只希望提取网络中某一层或者几层。</p>
<ul>
<li>nn.Module几个重要属性<ul>
<li>nn.Module.children() 返回下一级模块的迭代器，只会返回layer1,2,3,4</li>
<li>nn.Module.modules() 返回所有模块的迭代器，好处是能访问到最内层，比如self.layer1.conv1</li>
<li>与以上两个对应的下面两个，不仅会返回模块迭代器，还会返回网路层的名字<ul>
<li>nn.Module.named_children()</li>
<li>nn.Module.named_modules()<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">new_module = nn.Sequential(*list(model.children())[:<span class="number">2</span>]) <span class="comment">#提取模型前两层</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> model.named_modules():</span><br><span class="line">    <span class="keyword">if</span> isinstance(layer[<span class="number">1</span>], nn.Conv2d): <span class="comment"># isinstance判断是不是需要的类型实例</span></span><br><span class="line">        conv_model.add_module(layer[<span class="number">0</span>], layer[<span class="number">1</span>])  <span class="comment">#提取除所有的卷积模块(内层的)</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="4-3-4-如何提取参数及自定义初始化"><a href="#4-3-4-如何提取参数及自定义初始化" class="headerlink" title="4.3.4 如何提取参数及自定义初始化"></a>4.3.4 如何提取参数及自定义初始化</h3><p>提取层结构不够还需要对<strong>参数初始化</strong></p>
<ul>
<li>nn.Module特别重要关于参数的属性<ul>
<li>nn.Module.named_parameters() 给出网络层的名字和参数的迭代器</li>
<li>nn.Module.parameters() 给出一个网络的全部参数的迭代器<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    print(param[<span class="number">0</span>]) <span class="comment">#得到每一层参数的名字</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<p>对<strong>权重初始化</strong>，因为权重是一个Variable，只需要提取data属性再处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> model.modules():</span><br><span class="line">    <span class="keyword">if</span> isinstane(m, nn.Conv2d):</span><br><span class="line">        init.normal(m.weight.data)</span><br><span class="line">        init.xavier_normal(m.weight.data)</span><br><span class="line">        init.kaiming_normal(m.weight.data)</span><br><span class="line">        m.bias.data.fill_(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">elif</span> isinstane(m, nn.Linear):</span><br><span class="line">        m.weight.data.normal_()</span><br></pre></td></tr></table></figure>

<p><strong>上面参数就是权重，一种是parameter提取出名字，另一种是直接调用.weight属性修改</strong></p>
<h2 id="4-4-卷积神经网络案例分析"><a href="#4-4-卷积神经网络案例分析" class="headerlink" title="4.4 卷积神经网络案例分析"></a>4.4 卷积神经网络案例分析</h2><h3 id="4-4-1-LeNeT"><a href="#4-4-1-LeNeT" class="headerlink" title="4.4.1 LeNeT"></a>4.4.1 LeNeT</h3><blockquote>
<p>整个卷积神经网络的开山之作，1998年提出，结构简单，一共7层，其中2层卷积层和2层池化层教徒出现，最后三层全连接层得到整体的结果。层数很浅，没有添加激活层</p>
</blockquote>
<h3 id="4-4-2-AlexNet"><a href="#4-4-2-AlexNet" class="headerlink" title="4.4.2 AlexNet"></a>4.4.2 AlexNet</h3><blockquote>
<p>2012年在ImageNet竞赛上大放异彩的AlexNet。结构复杂因为当时GPU性能不好用了两个，现在可以用一个GPU替代。AlexNet网络层数更深，第一次引入激活层ReLu,全连接层引入Dropout层防止过拟合。</p>
</blockquote>
<h3 id="4-4-3-VGGNet"><a href="#4-4-3-VGGNet" class="headerlink" title="4.4.3 VGGNet"></a>4.4.3 VGGNet</h3><blockquote>
<p>2014年ImageNet竞赛亚军，总结用了更小的滤波器，更深的结构，AlexNet只有8层，而VGGNet有16层～19层，这就是运用多个小滤波器减少参数。</p>
</blockquote>
<h3 id="4-4-4-GoogLeNet"><a href="#4-4-4-GoogLeNet" class="headerlink" title="4.4.4 GoogLeNet"></a>4.4.4 GoogLeNet</h3><blockquote>
<p>2014年提出，如今进化到v4版本，最核心部分采取了比VGGNet更深的结构，一共有22层，但它的参数比AlexNet少了12倍，同时有很高的计算效率，因为采用了很有效的Inception模块，没有全连接层，是2014年比赛冠军。<br>Inception模块设计了一个局部的网络拓扑结构，然后将这些模块对别一起形成抽象层网络结构，具体来说是几个并行的滤波器对输入进行卷积和池化，这些滤波器有不同的感受野，最后按深度拼接一起形成输出层。<br>问题是参数较多，对这个版本有了Inception模块新设计。</p>
</blockquote>
<h3 id="4-4-5-ResNet"><a href="#4-4-5-ResNet" class="headerlink" title="4.4.5 ResNet"></a>4.4.5 ResNet</h3><ul>
<li>误差:即观测值与真实值的偏离;</li>
<li>残差:观测值与拟合值的偏离.<blockquote>
<p>2015年ImageNet竞赛冠军，由微软研究院提出，通过残差模块能欧成功地训练高达152层深的神经网络<br>残差学习单元相当于将学习莫表改变了，不再是学习一个完整的输出h(x)，而是学习输出和输入的差别H(x)-x，即残差。</p>
</blockquote>
</li>
</ul>
<p><strong><em>以上的模型都定义在torchvision里面，也有预训练好的参数，这些预训练好的网络为后面介绍的前一学习和微调做了很好的铺垫。</em></strong></p>
<h2 id="4-5-再实现MNIST手写数字分类"><a href="#4-5-再实现MNIST手写数字分类" class="headerlink" title="4.5 再实现MNIST手写数字分类"></a>4.5 再实现MNIST手写数字分类</h2><p>成功跑出了MNIST分类模型，挺激动的，就是电脑cpu太慢了，训练半天。</p>
<h2 id="4-6-图像增强的方法"><a href="#4-6-图像增强的方法" class="headerlink" title="4.6 图像增强的方法"></a>4.6 图像增强的方法</h2><p>前面专注于CNN的层结构，现在从另外的角度——图像增强的方面入手，提高模型的准确率和泛化能力。</p>
<ul>
<li>影响图像的因素<ul>
<li>拍摄的光照强度</li>
<li>物体的姿势</li>
<li>是否有遮蔽物</li>
</ul>
</li>
</ul>
<p><strong><em>针对这些问题，Torchvision.transforms包括所有图像增强的方法</em></strong></p>
<ul>
<li>torchvision.transforms图像增强的方法.<ol>
<li>Scale，对图片的尺度进行缩小和放大；</li>
<li>CenterCrop，对图片正中心进行给定大小的裁剪；</li>
<li>RandomCrop，对图片进行给定大小的随机裁剪；</li>
<li>RandomHorizaontalFlip，对图片进行概率为0.5的随机水平反转；</li>
<li>RandomSizedCrop，首先对图片进行随机尺寸的裁剪，然后对裁剪的图片进行一个随机比例的缩放，最后将图片边尘给定的大小，在InceptionNet中比较流行</li>
<li>pad对图片进行边界零填充<br>还有其他方法，可以用OpenCV或者PIL等第三方图形库实现。<h2 id="4-7-实现cifar10分类"><a href="#4-7-实现cifar10分类" class="headerlink" title="4.7 实现cifar10分类"></a>4.7 实现cifar10分类</h2></li>
</ol>
</li>
</ul>
<p><strong><em>下个星期再重点学习，先复习考试。</em></strong></p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/13/Pytorch文档阅读笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="望星的太阳花">
      <meta itemprop="description" content="You are my JavaSript in my HTML.">
      <meta itemprop="image" content="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1570163730249&di=dcd36b04d1066a90ddb1f132ae3a6bcc&imgtype=0&src=http%3A%2F%2Fhbimg.b0.upaiyun.com%2Ffe60497fd762440686b6d5702c2c9f19df71fb9911009-LVWEJj_fw658">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/10/13/Pytorch文档阅读笔记/" class="post-title-link" itemprop="url">Pytorch文档阅读笔记</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2019-10-13 23:09:35" itemprop="dateCreated datePublished" datetime="2019-10-13T23:09:35+08:00">2019-10-13</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-11 12:07:01" itemprop="dateModified" datetime="2020-02-11T12:07:01+08:00">2020-02-11</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep-Learning</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="PYTORCH-DOCUMENTATION"><a href="#PYTORCH-DOCUMENTATION" class="headerlink" title="PYTORCH DOCUMENTATION"></a>PYTORCH DOCUMENTATION</h1><h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><h3 id="Autograd-mechanics"><a href="#Autograd-mechanics" class="headerlink" title="Autograd mechanics"></a>Autograd mechanics</h3><ul>
<li><p><strong>自动的梯度传递过程，主要介绍requires_grad</strong></p>
<p>  可以用requires_grad来’freeze part of your model’<br>  底下model.fc就是最后一层的模型 这里将前面的冻结(梯度变为零，新的最后一层梯度为正)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"><span class="comment"># Replace the last fully-connected layer</span></span><br><span class="line"><span class="comment"># Parameters of newly constructed modules have requires_grad=True by default </span></span><br><span class="line">model.fc = nn.Linear(<span class="number">512</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimize only the classifier</span></span><br><span class="line">optimizer = optim.SGD(model.fc.parameters(), lr=<span class="number">1e-2</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>自动求道如何编码历史</p>
</li>
<li><p>不建议使用in-place操作<br><img src="/2019/10/13/Pytorch文档阅读笔记/in-place.png" alt="in-place"></p>
</li>
<li><p>可以用self.faved_tensors来检测是否正确：</p>
<blockquote>
<p>Once you access self.saved_tensors it is checked, and if it is greater than the saved value an error is raised. </p>
</blockquote>
</li>
</ul>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/10/深度学习总结/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="望星的太阳花">
      <meta itemprop="description" content="You are my JavaSript in my HTML.">
      <meta itemprop="image" content="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1570163730249&di=dcd36b04d1066a90ddb1f132ae3a6bcc&imgtype=0&src=http%3A%2F%2Fhbimg.b0.upaiyun.com%2Ffe60497fd762440686b6d5702c2c9f19df71fb9911009-LVWEJj_fw658">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/10/10/深度学习总结/" class="post-title-link" itemprop="url">深度学习总结</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2019-10-10 22:48:42" itemprop="dateCreated datePublished" datetime="2019-10-10T22:48:42+08:00">2019-10-10</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-11 12:05:29" itemprop="dateModified" datetime="2020-02-11T12:05:29+08:00">2020-02-11</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep-Learning</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="深度学习总结"><a href="#深度学习总结" class="headerlink" title="深度学习总结"></a>深度学习总结</h1><blockquote>
<p>不管怎么说也快挺长时间的人工智能，有困难的地方也有容易的地方，总结归纳下也许更利于提升。</p>
</blockquote>
<h2 id="1-深度学习的历史发展"><a href="#1-深度学习的历史发展" class="headerlink" title="1.深度学习的历史发展"></a>1.深度学习的历史发展</h2><p><img src="/2019/10/10/深度学习总结/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD.png" alt="Ai"></p>
<ul>
<li>数据挖掘就是在大型的数据库中发现有效信息的数据处理的过程。</li>
<li>机器学习是实现人工智能的一种途径，和数据挖掘有相似性。主要是通过算法的设计，让计算机能够自动地从数据中“学习规律”，利用规律进行预测。</li>
<li>深度学习最初版本是人工神经网络（机器学习的一个分支），试图通过模拟人脑，通过复杂的结构自动提取数据特征。</li>
</ul>
<p>而现在主要兴起的是深度学习，得益于大数据的兴起和高性能GPU的出现，使复杂的网络模型成为可能<br><img src="/2019/10/10/深度学习总结/DL%E5%8F%91%E5%B1%95.png" alt="Dl"></p>
<h2 id="2-机器学习总结"><a href="#2-机器学习总结" class="headerlink" title="2.机器学习总结"></a>2.机器学习总结</h2><blockquote>
<p>机器学习是基础。首先理解清楚机器学习中的一些概念算法。很多模型的建立都是根据复杂的数学模型得来的。</p>
</blockquote>
<h3 id="1、主要概念理解"><a href="#1、主要概念理解" class="headerlink" title="1、主要概念理解"></a>1、主要概念理解</h3><p><img src="/2019/10/10/深度学习总结/map.png" alt="map"></p>
<p>重要难理解的：</p>
<ul>
<li>KNN邻近算法，距离算法 找最近的邻居判断 属于什么类别 也可以做回归问题（多种判断） k是取的邻居数，距离算法的选择 ： 欧式距离 余弦距离 马斯距离 汉民距离 判断对新样本如何分类，可能必须缩放属性以防止距离度量被其中一个属性支配。</li>
<li>支持向量机：通过训练模型参数找到一个合适的分离界面将数据分离开。有松弛变量，惩罚函数，margin，多种范数距离，另有积分变换将多维降纬。</li>
<li>决策树，其中每个内部结点表示在一个属性上的测试对未知数据进行分类，每个分支代表一个属性输出，每个树叶结点代表类或类分布。根据分类最后叶子得到一个类。向前向后剪枝，信息熵增益，随机森林</li>
<li>集成方法 集成方法 就是用很多 简单分类器 来构造复杂的分类函数，原始样本的抽样：bagging 抽了之后放，Bosting 抽了之后 下一次再抽 就加权。多个弱分类器分出好的结果像盲人摸象。<h3 id="2、实战（python）"><a href="#2、实战（python）" class="headerlink" title="2、实战（python）"></a>2、实战（python）</h3><img src="/2019/10/10/深度学习总结/Ku.png" alt="ku"></li>
<li>numpy 包含矩阵运算，向量运算的包，扩展python的运算</li>
<li>Scipy 世界上著名的Python开源科学计算库，建立在Numpy上，它增加的功能包括数值积分、最优化、统计和一些专用函数。</li>
<li>pandas 数据集处理包，学习的数据存在数据集中，需要pandas处理</li>
<li>matplotlib 绘图用的包，数据可视化</li>
<li>seaborn 基于matplotlib的图形可视化python包。它提供了一种高度交互式界面,便于用户能够做出各种有吸引力的统计图表</li>
<li>scikit-learn 机器学习的包，包含了很多机器学习的模型与方法函数</li>
<li>OpenCv 图像处理的包，对图像的操作</li>
<li>TensorFlow与Pytorch 深度学习的框架</li>
</ul>
<p><strong><em>以上每个包都需要学习的大量的资料才能掌握</em></strong></p>
<h3 id="3、代码实现-基础框架"><a href="#3、代码实现-基础框架" class="headerlink" title="3、代码实现(基础框架)"></a>3、代码实现(基础框架)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np   <span class="comment">#导入numpy</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt     <span class="comment">#导入画图包</span></span><br><span class="line">x_data = np.array([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>])     <span class="comment">#手动创建三个数据</span></span><br><span class="line">y_data = np.array([<span class="number">1.968</span>, <span class="number">4.125</span>, <span class="number">5.671</span>])    </span><br><span class="line">plt.scatter(x_data,y_data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#define linear model </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x * w</span><br><span class="line">    <span class="comment"># Loss function </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    <span class="keyword">return</span> (y_pred - y) * (y_pred - y)</span><br><span class="line">    <span class="comment"># gradient function  </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient</span><span class="params">(x, y)</span>:</span>  <span class="comment"># d_loss/d_w</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span> * x * (x * w - y)</span><br><span class="line">    <span class="comment">#define parameters  </span></span><br><span class="line">w = <span class="number">1.0</span>  <span class="comment"># start points</span></span><br><span class="line">lr = <span class="number">0.001</span> <span class="comment">#learning rate</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Training loop </span></span><br><span class="line">i=<span class="number">1</span></span><br><span class="line">epochs=<span class="number">500</span></span><br><span class="line">weights=[]</span><br><span class="line">losses=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.arange(epochs):</span><br><span class="line">    <span class="keyword">for</span> x_val, y_val <span class="keyword">in</span> zip(x_data, y_data):  <span class="comment">#zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。</span></span><br><span class="line">        grad = gradient(x_val, y_val)</span><br><span class="line">        w = w - lr * grad</span><br><span class="line">        l = loss(x_val, y_val)</span><br><span class="line">    <span class="keyword">if</span> i%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">        weights+=[w]         </span><br><span class="line">        losses+=[l]          </span><br><span class="line">        print(<span class="string">"progress:"</span>, i, <span class="string">"w="</span>, round(w, <span class="number">2</span>), <span class="string">"loss="</span>, round(l, <span class="number">2</span>))   </span><br><span class="line">    <span class="keyword">if</span> np.linalg.norm(grad)&lt;=<span class="number">1e-6</span>: </span><br><span class="line">        <span class="keyword">break</span>  </span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="comment"># After training</span></span><br><span class="line">print(weights)</span><br><span class="line">print(losses)</span><br><span class="line">plt.plot(weights,losses) </span><br><span class="line">plt.plot(x_data,y_predict) </span><br><span class="line">plt.scatter(x_data,y_data)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2019/10/10/深度学习总结/simp1.png" alt="simp1"></p>
<h2 id="3-深度学习总结"><a href="#3-深度学习总结" class="headerlink" title="3.深度学习总结"></a>3.深度学习总结</h2><p>深度学习是现在主流的人工智能方向，是一种基于大数据和高性能Gpu的方法，有Pytorch和TensorFlow两种主流框架，现在学的是Pytorch</p>
<blockquote>
<p>PyTorch 是 Torch7 团队开发的，从它的名字就可以看出，其 与 Torch 的不同之处 在于 PyTorch 使用了 Python 作为开发语言 ζ 所谓 “Python first” ，同样说明它是 一 个以 Python 优先的深度学习框架，不仅能够实现强大的 GPU 加速，同时还支持功态神经网 络，这是现在很多主流框架比如 Tensorflow 等都不支持的。</p>
</blockquote>
<h3 id="1-多层全连接神经网络"><a href="#1-多层全连接神经网络" class="headerlink" title="1. 多层全连接神经网络"></a>1. 多层全连接神经网络</h3><p><img src="/2019/10/10/深度学习总结/ptha.png" alt="ptha"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#回归问题 线性回归 </span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn,optim</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#导入数据集</span></span><br><span class="line">x_train=np.array([[<span class="number">3.3</span>], [<span class="number">4.4</span>], [<span class="number">5.5</span>], [<span class="number">6.71</span>], [<span class="number">6.93</span>], [<span class="number">4.168</span>], [<span class="number">9.779</span>], [<span class="number">6.182</span>], [<span class="number">7.59</span>], [<span class="number">2.167</span>], [<span class="number">7.042</span>], [<span class="number">10.791</span>], [<span class="number">5.313</span>], [<span class="number">7.997</span>], [<span class="number">3.1</span>]], dtype=np.float32)</span><br><span class="line">y_train=np.array([[<span class="number">1.7</span>], [<span class="number">2.76</span>], [<span class="number">2.09</span>], [<span class="number">3.19</span>], [<span class="number">1.694</span>], [<span class="number">1.573</span>], [<span class="number">3.366</span>], [<span class="number">2.596</span>], [<span class="number">2.53</span>], [<span class="number">1.221</span>], [<span class="number">2.827</span>], [<span class="number">3.465</span>], [<span class="number">1.65</span>], [<span class="number">2.904</span>], [<span class="number">1.3</span>]], dtype=np.float32)</span><br><span class="line">plt.plot(x_train,y_train, <span class="string">'ro'</span>)</span><br><span class="line">x_train = torch.from_numpy(x_train)</span><br><span class="line">y_train = torch.from_numpy(y_train)</span><br></pre></td></tr></table></figure>

<p><img src="/2019/10/10/深度学习总结/p1.png" alt="p1"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearRegression</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(LinearRegression, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="number">1</span>,<span class="number">1</span>)  <span class="comment">#输入输出都是一维</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">1e-2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">num_epochs = <span class="number">1000</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">    inputs = Variable(x_train)</span><br><span class="line">    target = Variable(y_train)</span><br><span class="line">    <span class="comment">#forward</span></span><br><span class="line">    out=model(inputs)</span><br><span class="line">    loss=criterion(out, target)</span><br><span class="line">    <span class="comment">#backward</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="keyword">if</span> (epoch+<span class="number">1</span>) % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Epoch[&#123;&#125;/&#123;&#125;], loss:&#123;:.6f&#125;'</span>.format(epoch+<span class="number">1</span>, num_epochs, loss.item()))</span><br><span class="line"></span><br><span class="line"><span class="comment">#评估模型</span></span><br><span class="line">model.eval()  <span class="comment">#转变成eval的测试模式</span></span><br><span class="line">predict = model(Variable(x_train))</span><br><span class="line">predict = predict.data.numpy()  <span class="comment">#转numpy</span></span><br><span class="line">plt.plot(x_train.numpy(), y_train.numpy(), <span class="string">'ro'</span>, label=<span class="string">'Original data'</span>)</span><br><span class="line">plt.plot(x_train.numpy(), predict, label=<span class="string">'Fitting Line'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2019/10/10/深度学习总结/p2.png" alt="p2"></p>
<h3 id="2-其他流行网络"><a href="#2-其他流行网络" class="headerlink" title="2.其他流行网络"></a>2.其他流行网络</h3><ul>
<li>卷积神经网络（计算机视觉）</li>
<li>循环神经网络（基于记忆的网络模型——序列预测）</li>
<li>生成对抗网络（对抗网络就是让两个网络相互竞争，通过生成网络来生成假的数据，对抗网络通过判别器判别真伪，最后希望 生成网络生成的数据能够以假乱真骗过判别器 。）</li>
</ul>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/06/Eloquent-JavaScript学习笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="望星的太阳花">
      <meta itemprop="description" content="You are my JavaSript in my HTML.">
      <meta itemprop="image" content="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1570163730249&di=dcd36b04d1066a90ddb1f132ae3a6bcc&imgtype=0&src=http%3A%2F%2Fhbimg.b0.upaiyun.com%2Ffe60497fd762440686b6d5702c2c9f19df71fb9911009-LVWEJj_fw658">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/10/06/Eloquent-JavaScript学习笔记/" class="post-title-link" itemprop="url">Eloquent JavaScript学习笔记</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2019-10-06 19:37:22" itemprop="dateCreated datePublished" datetime="2019-10-06T19:37:22+08:00">2019-10-06</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-11 12:06:14" itemprop="dateModified" datetime="2020-02-11T12:06:14+08:00">2020-02-11</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Front-end/" itemprop="url" rel="index"><span itemprop="name">Front-end</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="神作Eloquent-JavaScript阅读笔记"><a href="#神作Eloquent-JavaScript阅读笔记" class="headerlink" title="神作Eloquent JavaScript阅读笔记"></a>神作Eloquent JavaScript阅读笔记</h1><h2 id="Chapter-1-Values-Types-and-Operators"><a href="#Chapter-1-Values-Types-and-Operators" class="headerlink" title="Chapter 1 Values, Types, and Operators"></a>Chapter 1 Values, Types, and Operators</h2><p>主要讲的js中数据的类型，同时有许多底层细节的地方值得注意。</p>
<ul>
<li><p>Numbers：</p>
<ul>
<li>范围小于2<sup>64<sup></sup></sup></li>
<li>但是有了负数和小数点，数据只能小于15个0</li>
<li>可以用科学计数法 2.998e8</li>
</ul>
</li>
<li><p>Special numbers：</p>
<ul>
<li>三个特殊的数:Infinity,-Infinity,NaN.</li>
<li>Infinity,-Infinity表示正无穷和负无穷，但不要太相信，很容易计算转化为NaN</li>
<li>NaN表示“不是一个数字”，当你操作0/0，∞-∞，或者没有意义的运算就会得到NaN</li>
</ul>
</li>
<li><p>Strings:</p>
<ul>
<li>有三种格式 单引号’’，双引号”” 和反引号 ``</li>
<li>首先注意反引号：<ul>
<li>用反引号圈起来里面可以用回车不被转义<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/s1.png" alt="s1"></li>
<li>反引号里面能包含变量<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/s2.png" alt="s2"></li>
</ul>
</li>
<li>再就是转义字符：<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/s3.png" alt="s3"></li>
</ul>
</li>
<li><p>Comparison：</p>
<ul>
<li><code>console.log(NaN == NaN)</code>结果是假，因为NaN应该表示无意义计算的结果，因此，它不等于任何其他无意义计算的结果。</li>
</ul>
</li>
<li><p>Logical operators<br> -注意优先级：<br> -|| has the lowest precedence, then comes &amp;&amp;, then the comparison operators (&gt;, ==, and so on), and then the rest.</p>
</li>
<li><p>Empty values:</p>
<ul>
<li>空值，有两个undefined和null 大部分时间不区分 可看作可以交换的，表示没有值，但必须存在</li>
</ul>
</li>
<li><p>Automatic type conversion:<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/a1.png" alt="a1"></p>
<ul>
<li>上述，类型转换，值得注意的：<ul>
<li>当左右边有null或者undefined 必须两边都是才能真 否则为假<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/a2.png" alt="a2"></li>
</ul>
</li>
<li>同时你要严格一点就使用=== 和 !==,除非比较的类型是一样的，否则建议使用三元的</li>
</ul>
</li>
<li><p>Short-circuiting of logical operators</p>
<ul>
<li>这个很厉害（逻辑运算符短路）<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/sc1.png" alt="sc1"></li>
<li>简单说就是上述，当你这样子并起来你左边的值为空的话可以把右边的值当备选，实用</li>
<li>还有是同c语言当&amp;&amp;的左边为假右边不看，当||的左边为真右边不看，短路<h2 id="Chapter-2-Program-Structure"><a href="#Chapter-2-Program-Structure" class="headerlink" title="Chapter 2 Program Structure"></a>Chapter 2 Program Structure</h2>第一章是基础数值，这里说明编程的结构</li>
</ul>
</li>
<li><p>Bindings</p>
<ul>
<li>绑定的概念，用关键字let,const,var</li>
<li>形象的概念：您会长出一个触手来抓住它，或者将现有的触手重新连接到它上。有可能同时绑定到同一个值</li>
<li>命名规则：<ul>
<li>可以有数字和字母，不能数字开头</li>
<li>A binding name may include dollar signs ($) or underscores (_) but no other punctuation or special characters.</li>
<li>不能关键字</li>
</ul>
</li>
</ul>
</li>
<li><p>The Environment </p>
<ul>
<li>环境的概念:</li>
<li>在给定时间存在的绑定及其值的集合称为环境。 程序启动时，此环境不为空。 它始终包含作为语言标准一部分的绑定，并且在大多数情况下，它还具有提供与周围系统进行交互的方式的绑定。 例如，在浏览器中，具有与当前加载的网站进行交互以及读取鼠标和键盘输入的功能。</li>
<li>理解是与环境有关的绑定集合：绑定可用于以名称命名文件数据，它们对于跟踪程序中的状态很有用。 环境是定义的绑定集。 JavaScript系统始终在您的环境中放置许多有用的标准绑定。</li>
</ul>
</li>
<li><p>The console.log function</p>
<ul>
<li>不寻常的绑定，是一个console控制台的绑定</li>
<li>This is because console.log isn’t a simple binding. It is actually an expression that retrieves the log property from the value held by the console binding.</li>
<li>正常的绑定无.</li>
</ul>
</li>
<li><p>Return values</p>
<ul>
<li>这种不知道怎么说，就是说不是return 而用console.log来实现的叫做side effect</li>
<li>显示对话框或在屏幕上写文本是一种副作用。 由于它们产生的副作用，许多功能很有用。 函数也可以产生值，在这种情况下，它们不需要产生副作用即可使用。 例如，函数Math.max接受任意数量的数字参数并返回最大值。</li>
<li>⬆️翻译是副作用，就是不是返回的值</li>
</ul>
</li>
<li><p>Capitalization：</p>
<ul>
<li>命名方法<br>— 推荐是小驼峰，开头是小写</li>
<li>js里面没有其他面向对象语言的类概念，而是constructor 构造函数的概念，构造函数命名要大写<h2 id="Chapter-3-Functions"><a href="#Chapter-3-Functions" class="headerlink" title="Chapter 3 Functions"></a>Chapter 3 Functions</h2></li>
</ul>
</li>
<li><p>Bindings and scopes</p>
<ul>
<li>绑定和作用域</li>
<li>let和const(一直存在在程序运行的)会是严格的局部作用域，var会是全局的导致问题<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/c1.png" alt="c1"></li>
</ul>
</li>
<li><p>Nested scope</p>
<ul>
<li>嵌套作用域<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/n1.png" alt="n1"></li>
<li>块内部可见的绑定集由该块在程序文本中的位置确定。 每个本地范围也可以看到包含它的所有本地范围，并且所有范围都可以看到全局范围。 这种绑定可见性的方法称为词法作用域。</li>
</ul>
</li>
<li><p>Functions as values</p>
<ul>
<li>函数和值，你可以把函数定义成一个值，有时候会混淆，但是函数的概念是可以传入值来执行一个操作的</li>
</ul>
</li>
<li><p>Declaration notation</p>
<ul>
<li>js里面含糊不是从上而下的，可以先使用再定义</li>
</ul>
</li>
<li><p>Arrow functions</p>
<ul>
<li>箭头函数：四种定义使用方法</li>
<li>一种正常，参数多，表达式多<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/ar1.png" alt="ar1"></li>
<li>两种省略形式，参数一个或者表达式简单（直接返回）<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/ar2.png" alt="ar2"></li>
<li>一种，没有参数，要写空括号<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/ar3.png" alt="ar3"></li>
</ul>
</li>
<li><p>The call stack</p>
<ul>
<li>说明调用和调用返回的原理</li>
<li>存储该堆栈需要计算机内存中的空间。 当堆栈太大时，计算机将失败，并显示诸如“堆栈空间不足”或“递归过多”之类的消息。 下面的代码通过向计算机提出一个非常棘手的问题来说明这一点，该问题会导致两个函数之间的无限往返。 相反，如果计算机具有无限的堆栈，那将是无限的。 照原样，我们将用完空间，或“破坏堆栈”。</li>
</ul>
</li>
<li><p>Optional Arguments</p>
<ul>
<li>实用的，相当于函数重载，更加方便</li>
<li>js函数对参数的原则：如果通过太多，多余的将被忽略。 如果传递的参数太少，则会为缺失的参数分配未定义的值。</li>
<li>下面两种就是具体的用法<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">minus</span>(<span class="params">a, b</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (b === <span class="literal">undefined</span>) <span class="keyword">return</span> -a;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">return</span> a - b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">power</span>(<span class="params">base, exponent = <span class="number">2</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">let</span> result = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">let</span> count = <span class="number">0</span>; count &lt; exponent; count++) &#123;</span><br><span class="line">    result *= base;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(power(<span class="number">4</span>));</span><br><span class="line"><span class="comment">// → 16</span></span><br><span class="line"><span class="built_in">console</span>.log(power(<span class="number">2</span>, <span class="number">6</span>));</span><br><span class="line"><span class="comment">// → 64</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Closure</p>
<ul>
<li>封装的问题，当你再次绑定时会更新局部变量绑定，所以不必要担心绑定的生命周期<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/cl1.png" alt="cl1"></li>
<li>高级是：考虑这样的程序需要一些练习。 一个好的思维模型是将函数值视为包含其主体代码和创建它们的环境的代码。 调用函数体时，它会看到在其中创建它的环境，而不是在其中看到它的环境。<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/cl2.png" alt="cl2"></li>
</ul>
</li>
<li><p>Recursion</p>
<ul>
<li>回调函数，定义类似，可以让代码更优雅，但是代价可能比循环跑的更慢，但是作者建议用回调便于代码阅读。<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/r1.png" alt="r1"></li>
<li>这种就很优雅很强大<h2 id="Chapter-4-Data-Structures-Objects-and-Arrays"><a href="#Chapter-4-Data-Structures-Objects-and-Arrays" class="headerlink" title="Chapter 4 Data Structures: Objects and Arrays"></a>Chapter 4 Data Structures: Objects and Arrays</h2>这一章主要讲了对象和数组，是用一个实际的一个人会因为做那些事情导致变成松鼠的例子来解释的，最后找到是因为吃了坚果不刷牙会变成松鼠，有很多数组的操作和对象的处理方法，只可意会不可言传。</li>
</ul>
</li>
<li><p>Properties</p>
<ul>
<li>翻译是属性，这里注意两种使用方法，它们都可以绑定到value对象的属性担有不同：<ul>
<li>value.x（只能是显式的已经存在的方法）</li>
<li>value[x]（这个x是可以是表达式或者变量可以变化的值）</li>
<li>数组中的元素存储为数组的属性，使用数字作为属性名称。 因为您不能将点符号与数字一起使用，并且通常希望使用无论如何都可容纳索引的绑定，所以必须使用方括号符号来获取它们。</li>
</ul>
</li>
</ul>
</li>
<li><p>Methods</p>
<ul>
<li>方法<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/m1.png" alt="m1"></li>
<li>有趣的是，即使对toUpperCase的调用未传递任何参数，该函数仍可以访问字符串“ Doh”，即我们调用其属性的值。 第6章介绍了它的工作方式。</li>
</ul>
</li>
<li><p>Objects</p>
<ul>
<li>类型对象的值是属性的任意集合。 创建对象的一种方法是使用大括号作为表达式。</li>
<li>在大括号内，有一个由逗号分隔的属性列表。 每个属性都有一个名称，后跟一个冒号和一个值。 当对象被写在多行上时，像示例中那样缩进可以提高可读性。 名称不是有效绑定名称或有效数字的属性必须加引号。</li>
</ul>
</li>
<li><p>Mutability</p>
<ul>
<li>前面普通类型的值不能变，对象的值是可以变的</li>
<li>绑定也可以是可变的或恒定的，但这与它们的值的行为方式是分开的。 即使数字值不变，您也可以使用let绑定通过更改绑定点所指向的值来跟踪变化的数字。 同样，尽管绑定到对象的const本身不能更改，并且将继续指向同一对象，但是该对象的内容可能会更改。<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/mu1.png" alt="mu1"></li>
</ul>
</li>
<li><p>The lycanthrope’s log</p>
<ul>
<li>一种简写对象的方式<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/t1.png" alt="t1"></li>
</ul>
</li>
<li><p>Array loops</p>
<ul>
<li>简单不用for循环的方法 用 let of<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/arr1.png" alt="arr1"></li>
</ul>
</li>
<li><p>Further arrayology</p>
<ul>
<li>简单的说明了多种array的方法<ul>
<li>shift</li>
<li>unshift</li>
<li>indexOf</li>
<li>lastIndexof</li>
<li>slice</li>
<li>contact</li>
</ul>
</li>
</ul>
</li>
<li><p>Strings and their properties</p>
<ul>
<li>字符串虽然可以看成对象，但他们不能随便乱给属性和方法，常用可行的方法是index和slice<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/sl1.png" alt="sl1"></li>
<li>The trim method removes whitespace (spaces, newlines, tabs, and similar characters) from the start and end of a string. 去除空格换行tab和类似的东西</li>
<li>You can split a string on every occurrence of another string with split and join it again with join.拆分和合并</li>
<li>我们已经看到了字符串类型的length属性。 访问字符串中的各个字符看起来就像访问数组元素（有关警告，我们将在第5章中进行讨论）。虽然用下标可以访问但有潜在警告</li>
</ul>
</li>
<li><p>Rest parameters</p>
<ul>
<li>接受任意的参数值 很有用<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/re1.png" alt="re1"></li>
<li>let words = [“never”, “fully”];<br>console.log([“will”, …words, “understand”]);<br>// → [“will”, “never”, “fully”, “understand”]</li>
<li>这会将数组“扩展”到函数调用中，并将其元素作为单独的参数传递。<h2 id="Chapter-5-Higher-Order-Functions"><a href="#Chapter-5-Higher-Order-Functions" class="headerlink" title="Chapter 5 Higher-Order Functions"></a>Chapter 5 Higher-Order Functions</h2>讲解如何写出高阶的函数，就是说不仅仅是给一个参数返回一个值</li>
</ul>
</li>
<li><p>Higher-order functions</p>
<ul>
<li>we can have functions that create new functions.<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/51.png" alt="51"></li>
<li>we can have functions that change other functions.<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/52.png" alt="52"></li>
<li>We can even write functions that provide new types of control flow.<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/53.png" alt="53"></li>
<li>There is a built-in array method, forEach, that provides something like a for/of loop as a higher-order function.<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/54.png" alt="54"></li>
</ul>
</li>
<li><p>Script data set</p>
<ul>
<li>SCRIPT数据集 包含了多国的不同unicode<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> &#123;</span><br><span class="line">name: <span class="string">"Coptic"</span>,</span><br><span class="line">ranges: [[<span class="number">994</span>, <span class="number">1008</span>], [<span class="number">11392</span>, <span class="number">11508</span>], [<span class="number">11513</span>, <span class="number">11520</span>]],</span><br><span class="line">direction: <span class="string">"ltr"</span>,</span><br><span class="line">year: <span class="number">-200</span>,</span><br><span class="line">living: <span class="literal">false</span>,</span><br><span class="line">link: <span class="string">"https://en.wikipedia.org/wiki/Coptic_alphabet"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Filtering arrays</p>
<ul>
<li>filter只读不会改变 ， map可以改变array的值</li>
</ul>
</li>
<li><p>Summarizing with reduce</p>
<ul>
<li>reduece通过重复从数组中获取单个元素并将其与当前值组合来构建值。在对数字求和时，您将从数字零开始，然后将每个元素加到总和中。<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/re.png" alt="re"></li>
</ul>
</li>
<li><p>Composability</p>
<ul>
<li>通常，您可以负担得起可读的方法，但是如果您要处理大量数组并且进行多次，那么抽象度较低的样式可能值得增加速度。<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/func1.png" alt="func1"><br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/func2.png" alt="func2"></li>
</ul>
</li>
</ul>
<h2 id="Chapter-6-The-Secret-Life-of-Objects"><a href="#Chapter-6-The-Secret-Life-of-Objects" class="headerlink" title="Chapter 6 The Secret Life of Objects"></a>Chapter 6 The Secret Life of Objects</h2><p>讲解js里对象的概念，由于js最开始没有内置这种东西，就衍生出许多方法来使用对象，之后才添加完善</p>
<ul>
<li>Encapsulation<ul>
<li>封装</li>
<li>一个类包含私有的和公共的，包含属性与方法，将整体封装起来，外界不需要知道内部的结构就可以直接调用方法使用一些功能</li>
</ul>
</li>
<li>Prototypes<ul>
<li>js里面很重要的继承了原生类，就是当你类没有调用的方法就会到原生类中去搜索使用，原型是另一个用作属性的备用源的对象。<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/p1.png" alt="p1"></li>
</ul>
</li>
<li>Methods<ul>
<li>注意function里面this的使用</li>
<li>this就相当于额外传递了参数（集成了类），而不仅仅括号传递的，因此每个function调用的时候就必须指定一this(bind)</li>
<li>当你一个函数里面调用另外一个函数，另外函数就就不能用this会报错，但是箭头函数可以（默认绑定附近作用域的this）<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/ab.png" alt="ab"></li>
</ul>
</li>
<li>Class Notion<ul>
<li>因此，JavaScript类是具有原型属性的构造函数。 它们就是这样工作的，直到2015年，您才必须编写它们。 这些天，我们有了一个不太尴尬的表示法。<br><img src="/2019/10/06/Eloquent-JavaScript学习笔记/clas.png" alt="clas"></li>
</ul>
</li>
</ul>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1570163730249&di=dcd36b04d1066a90ddb1f132ae3a6bcc&imgtype=0&src=http%3A%2F%2Fhbimg.b0.upaiyun.com%2Ffe60497fd762440686b6d5702c2c9f19df71fb9911009-LVWEJj_fw658"
      alt="望星的太阳花">
  <p class="site-author-name" itemprop="name">望星的太阳花</p>
  <div class="site-description" itemprop="description">You are my JavaSript in my HTML.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">望星的太阳花</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.4.1</div>

        












        
      </div>
    </footer>
  </div>

  
    
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.1"></script><script src="/js/motion.js?v=7.4.1"></script>
<script src="/js/schemes/muse.js?v=7.4.1"></script>

<script src="/js/next-boot.js?v=7.4.1"></script>



  





















  

  

  

</body>
</html>
